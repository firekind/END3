{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EVA P2S3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/firekind/END3/blob/main/session-4/quiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc66462-0e41-466a-c2df-ad6e69ffcfd8"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return y * (1-y)\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - y * y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wd6HTJpOFNv"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0UxR_7xOGxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b37e15-7d4a-48f1-85a3-567410ed383a"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrR5pQXsOHN6"
      },
      "source": [
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fg_7oFkOJ0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34db78e6-396f-4c00-fbd7-e5e996c51a76"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ixsaJJ4OKIJ"
      },
      "source": [
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Tn6gOdOOar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0443c9eb-e709-4ef5-e156-d09badc6387d"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370913"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNlM3piiOR4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9102a970-0b6c-474f-95e9-e74fe40f806e"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size # write your code here\n",
        "size_c = X_size # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o97sLBzDPrDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ddd1ed8-472b-478c-a487-e4579faa3224"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9OL4yC5Pzw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef3f2eb-bdc3-4513-f40f-5ca9560b30f8"
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "2d354ba9-230b-4119-a581-196967954775"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            " upptran stath. The fere hopreapinwts avely. He is acsod wauses are shered for for thanas, Driffed.\n",
            "\n",
            "Is them puscich countr emacion to the Rersobyon of be ivatity to Lrauth.\n",
            "\n",
            "Aron in how in trages. The \n",
            "----\n",
            "iter 49900, loss 5.415998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}